{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorLy, the syntax is very similar. The difference is that, depending on the backend, tensor will be NumPy arrays, pytorch tensors, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tl.tensor(np.arange(24).reshape((3, 4, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.],\n",
       "        [ 2.,  3.],\n",
       "        [ 4.,  5.],\n",
       "        [ 6.,  7.]],\n",
       "\n",
       "       [[ 8.,  9.],\n",
       "        [10., 11.],\n",
       "        [12., 13.],\n",
       "        [14., 15.]],\n",
       "\n",
       "       [[16., 17.],\n",
       "        [18., 19.],\n",
       "        [20., 21.],\n",
       "        [22., 23.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the frontal slices by fixing the last axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  2.,  4.,  6.],\n",
       "       [ 8., 10., 12., 14.],\n",
       "       [16., 18., 20., 22.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  5.,  7.],\n",
       "       [ 9., 11., 13., 15.],\n",
       "       [17., 19., 21., 23.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Setting the backend\n",
    "\n",
    "In TensorLy you can dynamically set the backend to use either NumPy or MXNet to represent tensors and perform the operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the backend is set to NumPy, here is how to change it, first to PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pytorch backend.\n"
     ]
    }
   ],
   "source": [
    "tl.set_backend('pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tl.tensor(np.arange(24).reshape((3, 4, 2)))\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected tensors are now represented as a PyTorch tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change it back to NumPy for the rest of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    }
   ],
   "source": [
    "tl.set_backend('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tl.tensor(np.arange(24).reshape((3, 4, 2)))\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Basic tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Unfolding\n",
    "\n",
    "Also called **matrization**, **unfolding** a tensor is done by reading the element in a given way as to obtain a matrix instead of a tensor.\n",
    "\n",
    "It is done by stacking the **fibers** of the tensor into a matrix.\n",
    "\n",
    "![tensor_illustration](images/example-unfolding-fibers.png)\n",
    "\n",
    "\n",
    "### Convention\n",
    "\n",
    "   Rememeer that, to be consistent with the Python indexing that always starts at zero,\n",
    "   in tensorly, unfolding also starts at zero!\n",
    "\n",
    "   Therefore ``unfold(tensor, 0)`` will unfold said tensor along its first dimension!\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
       "       [16., 17., 18., 19., 20., 21., 22., 23.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.unfold(X, mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  8.,  9., 16., 17.],\n",
       "       [ 2.,  3., 10., 11., 18., 19.],\n",
       "       [ 4.,  5., 12., 13., 20., 21.],\n",
       "       [ 6.,  7., 14., 15., 22., 23.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.unfold(X, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20., 22.],\n",
       "       [ 1.,  3.,  5.,  7.,  9., 11., 13., 15., 17., 19., 21., 23.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.unfold(X, mode=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Folding\n",
    "\n",
    "Folding is the inverse operation: you can **fold** an unfolded tensor back from matrix to full tensor using the ``tensorly.fold`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.],\n",
       "        [ 2.,  3.],\n",
       "        [ 4.,  5.],\n",
       "        [ 6.,  7.]],\n",
       "\n",
       "       [[ 8.,  9.],\n",
       "        [10., 11.],\n",
       "        [12., 13.],\n",
       "        [14., 15.]],\n",
       "\n",
       "       [[16., 17.],\n",
       "        [18., 19.],\n",
       "        [20., 21.],\n",
       "        [22., 23.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolding = tl.unfold(X, 1)\n",
    "original_shape = X.shape\n",
    "tl.fold(unfolding, mode=1, shape=original_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 n-mode product\n",
    "\n",
    "Also known as **tensor contraction**. This is a natural generalization of matrix-vector and matrix-matrix product. When multiplying a tensor by a matrix or a vector, we now have to specify the **mode** $n$ along which to take the product.\n",
    "### Tensor times matrix\n",
    "\n",
    "In that case we are doing an operation analogous to a matrix multiplication on the $n$-th mode. Given a tensor $\\tilde X$ of size $(I_0, I_1, \\cdots, I_N)$, and a matrix $M$ of size $(D, I_n)$, the $n$-mode product of $\\tilde X$ by $M$ is written $\\tilde X \\times_n M$ and is of size $(I_k, I_0 \\times \\cdots \\times I_{n-1} \\times D \\times I_{n+1} \\cdots \\times I_n)$.\n",
    "\n",
    "### Tensor times vector\n",
    "\n",
    "In that case we are contracting over the $n$-th mode by multiplying it with a vector. Given a tensor $\\tilde X$ of size $(I_0, I_1, \\cdots, I_N)$, and a vector $v$ of size $(I_n)$, the $n$-mode product of $\\tilde X$ by $v$ is written $\\tilde X \\times_n v$ and is of size $(I_k, I_0 \\times \\cdots \\times I_{n-1} \\times I_{n+1} \\cdots \\times I_n)$.\n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "In TensorLy, all the tensor algebra functions are located in the `tensorly.tenalg` module. For the n-mode product, you will need to use the function `mode_dot` that works transparently for multiplying a tensor by a matrix or a vector along a given mode.\n",
    "\n",
    "#### Tensor times matrix\n",
    "\n",
    "With the tensor $\\tilde X$ of size (3, 4, 2) we defined previously, let's define a matrix M of size (5, 4) to multiply along the second mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "M = tl.tensor(np.arange(4*5).reshape((5, 4)))\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind indexing starts at zero, so the second mode is represented by `mode=1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tl.tenalg.mode_dot(X, M, mode=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the result is of shape (3, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor times vector\n",
    "\n",
    "Similarly, we can contract along the mode 1 with a vector of size 4 (our tensor is of size (3, 4, 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "v = tl.tensor(np.arange(4))\n",
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = tl.tenalg.mode_dot(X, v, mode=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have multiplied by a vector, we have effectively contracted out one mode of the tensor so the result is a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kronecker and Khatri-Rao product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly.tenalg import kronecker, khatri_rao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tl.tensor([[2, 1],\n",
    "               [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = tl.tensor([[0.5, 1],\n",
    "               [2, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kronecker and Khatri-Rao product take as input a list of matrices (as they can take the kronecker and khatri-rao product of more than one matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "AB=\n",
      " [[1.  2.  0.5 1. ]\n",
      " [4.  0.  2.  0. ]\n",
      " [1.5 3.  2.  4. ]\n",
      " [6.  0.  8.  0. ]]\n",
      "    \n",
      "BA=\n",
      " [[1.  0.5 2.  1. ]\n",
      " [1.5 2.  3.  4. ]\n",
      " [4.  2.  0.  0. ]\n",
      " [6.  8.  0.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "kronecker([A, B])\n",
    "print('----')\n",
    "print('AB=\\n',kronecker([A, B]))\n",
    "print('    ')\n",
    "print('BA=\\n',kronecker([B, A]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 1. ],\n",
       "       [4. , 0. ],\n",
       "       [1.5, 4. ],\n",
       "       [6. , 0. ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khatri_rao([A, B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that to the result shown in the slides :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
